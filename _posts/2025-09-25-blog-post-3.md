---
title: "The Right to Be an Exception (and why averages shouldn’t run our lives)"
date: 2025-09-25
permalink: /posts/2025/09/right-to-be-an-exception/
tags:
  - ai-ethics
  - governance
  - uncertainty
  - fairness
---

**Article Reading:**  
[The Right to Be an Exception to a Data-Driven Rule — Sarah H. Cen & Manish Raghavan](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)  

---

## Summary

This case study makes the case that individuals deserve a **right to be an exception** when algorithms are making life-changing calls—like who gets a job, a loan, or parole. Instead of assuming a model works for everyone, decision makers should have to prove it’s appropriate for *this* person, weighing individualization, uncertainty, and the risk of harm.

---

## Discussion

**1) What is a data-driven rule, and what does it mean to be a data-driven exception? Is an exception the same as an error?**  
A data-driven rule is just the model’s recipe: inputs in, output out. An exception is someone the recipe doesn’t capture well, even if the model looks accurate overall. That’s not always the same as an error—sometimes the prediction is technically “right,” but it still wasn’t justified to apply that rule to this person.  
*This reminded me of finance models I’ve worked with: backtests can look amazing, but certain environments flip the logic upside down. If you’re in that environment, you’re the exception, even if the model gets the next trade technically correct.*

---

**2) In addition to those listed above, what other factors differentiate data-driven decisions from human ones?**  
- Algorithms repeat the **same blind spots** at scale, while human mistakes are more random.  
- Once organizations adopt a model, they tend to **standardize** around it—exceptions get squeezed out.  
- Humans can explain their thinking; models just spit out a score.  
- Algorithms work fast and consistently, which is great… until the wrong call is made, and then it’s systemically wrong.

---

**3) Beyond what is discussed above, what are some of the benefits and downsides of individualization?**  
**Upsides:** It feels fairer, it uses features that actually apply to *me*, and it gives clearer “recourse” (what to change for next time).  
**Downsides:** It can mean giving up more personal data, it can encourage gaming the system (“get this credential to pass the filter”), and it makes models harder to monitor or audit. Plus, more detail doesn’t always equal better—sometimes it just means overfitting.

---

**4) Why is uncertainty so critical to the right to be an exception? Can accuracy alone justify high-stakes use?**  
Uncertainty is the real gatekeeper. Some uncertainty comes from missing knowledge (epistemic), some from randomness itself (aleatoric). Either way, if the harm is high, you can’t just lean on “95% accuracy” and call it a day—because that still means 1 in 20 people could be harmed. Accuracy without uncertainty checks isn’t enough when the stakes are people’s freedom, housing, or healthcare.

---

## New question

**Question:** If we really enforce a right to be an exception, who absorbs the cost of the extra reviews and processes—organizations (more staff and audits), the public (slower services), or individuals (appeals time)?  

**Why I chose it:** The framework sounds solid, but in practice, fairness takes resources. Asking who should shoulder those costs pushes us to think about the messy trade-offs behind implementation.

---

## Reflection

This case study hit home for me. In the modeling world, it’s almost always the tail cases—the “exceptions”—that break your system, not the average ones. Applying that mindset to society, it’s clear we can’t just wave off those edge cases when harm is huge. The big idea here is shifting the **burden of proof**: it shouldn’t be on the individual to prove they deserve fair treatment; it should be on the decision maker to prove the model is actually fit to use on them. That shift feels both ethical and practical.

---