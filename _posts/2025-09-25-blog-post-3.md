---
title: "The Right to Be an Exception to a Data-Driven Rule"
date: 2025-09-25
permalink: /posts/2025/09/right-to-be-an-exception/
tags:
  - ai-ethics
  - governance
  - uncertainty
  - fairness
---

**Article Reading:**  
[The Right to Be an Exception to a Data-Driven Rule — Sarah H. Cen & Manish Raghavan](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)  

---

## Summary  
This case study argues that people should have the right to be treated as exceptions when algorithms are making major decisions about their lives. Even if a model performs well overall, it doesn’t always fit the individual in front of it. The core idea is shifting the burden: it shouldn’t be on people to prove they deserve fair treatment, but on the decision maker to show the model is appropriate and safe for that person.

## Discussion  
Data-driven systems work like recipes—plug in features, get an output. But people aren’t that uniform. A model can be “accurate” and still fail someone because their situation falls outside what the system understands. I kept thinking about trading models: most of the time they look great, but edge cases expose where they don’t apply. Being an exception isn’t the same as being an error; it’s just being in one of those edge conditions.

Algorithms also behave differently from humans. They repeat the same mistake exactly, at scale, and organizations tend to trust them once they’re adopted. They move fast, which is great until the stakes are high and uncertainty kicks in. A 95% accurate system still harms 1 in 20 people when the cost of being wrong is housing, healthcare, or freedom.

Individualization sounds like the fix—treating people based on their real circumstances. It feels fairer and helps people understand what they can change. But it also raises practical issues: more data collection, the risk of gaming the system, and more complexity for organizations trying to manage all of it.

One challenge the case study made me think about is who pays for fairness. Adding reviews, appeals, or human oversight costs time and money. Whether that burden falls on organizations, the public, or individuals decides how realistic this “right to be an exception” actually is.

## Reflection  
What stuck with me most is how similar this is to modeling in general. Systems don’t break on the average case—they break on the exceptions. Ignoring those exceptions is easy until the harm becomes real. Flipping the burden of proof feels both fair and practical: if a model is going to make a high-stakes decision about someone, the people using it should prove it works for *them*, not just for most people.