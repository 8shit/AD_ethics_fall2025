---
title: "Complete Delete: When “Delete” Is a Lie"
date: 2025-12-2
permalink: /posts/2025/12/blog11/
tags:
  - ethics
  - delete
collection: blogs
---

**Article Reading:**  
[Complete Delete: In Practice, Clicking 'Delete' Rarely Deletes. Should it? - Simson Garfinkel](https://mit-serc.pubpub.org/pub/fesqymtr/release/3?readingCollection=ca73f7c0)  

---

## Summary  
The case study “Complete Delete: In Practice, Clicking ‘Delete’ Rarely Deletes” explains how deleting a file does not actually erase it from most modern systems. Because of backups, cloud synchronization, and remnant data stored on physical devices, information often continues to exist long after users believe it is gone. The study raises ethical concerns about privacy, consent, and whether users truly have control over their own data.


## Discussion: Environmental Impact  
What stood out to me immediately is how misleading the word “delete” really is. As a user, when I delete something, I assume it is gone. But this case study shows that in reality, copies of that same data can live on across backup drives, cloud servers, and even offline storage for months or years. That disconnect between what users think deletion means and what actually happens feels like a serious violation of trust. The technology is designed for convenience and data preservation, not for respecting the user’s intent to erase something completely.

This becomes especially troubling when the data is sensitive. The case study talks about intimate images, private messages, and personal files that people assume they have erased, only for them to remain recoverable through digital forensics. Knowing that something you tried to permanently remove can still exist somewhere without your knowledge feels unsettling. It shifts power away from the individual and into the hands of corporations, system designers, and sometimes law enforcement. From my perspective, privacy should not be something that only exists until a backup syncs.

On a personal level, I rely on my phone and computer every day, and I usually upgrade every four to five years. I never really thought about what happens to my data beyond surface level cloud storage. I assumed that if something is deleted, it is just gone. Reading this made me realize how naive that assumption is. It is genuinely scary to think that the information I have created over years could still exist in places I do not even remember. And what is worse is that users are rarely warned clearly about this reality.

I also feel a deep frustration with how this problem is treated as a user behavior issue instead of a system design issue. The technology already exists for cryptographic erasure and secure deletion, yet it is often not fully implemented because of performance costs or battery life. But why should efficiency always outweigh a person’s right to truly erase their own data? It feels like another example of corporations prioritizing optimization and profit while pushing the privacy risks onto consumers who have very little real control.

There is also a larger power issue here. Regular users do not get to decide how deletion policies work. Engineers, product managers, and corporations do. Even when options exist, they are buried in settings that most people will never fully understand. And realistically, as consumers, we do not have the power to demand better systems unless governments step in. I personally place most responsibility on corporations and governments here. Corporations are driven by profit, and governments are slow to regulate, often weakened by corruption or lobbying. The individual user ends up trapped in a system they depend on but cannot meaningfully control.

At the same time, I feel stuck in a contradiction. I need modern technology to stay relevant academically, socially, and professionally. I do not really have the option to opt out. Even when I am aware of the risks, the system is structured so that participation is almost mandatory. That is what makes this issue so uncomfortable. Awareness does not automatically translate into power to change it.

## My Discussion Question  
If complete and irreversible deletion is technically possible, but rarely implemented due to cost and convenience, should governments legally require companies to prioritize true user controlled data deletion, even if it slows systems down or reduces profit?

I chose this question because it targets the real tension in the case study. The issue is no longer whether secure deletion is possible. It is whether powerful institutions are willing to make it a standard.

## Reflection
This case study changed the way I think about digital ownership. I always believed that data belonged to the person who created it. Now I realize that once something enters a digital system, true ownership becomes blurred. The idea that information can outlive my intent to erase it feels like a loss of autonomy in a space where I assumed I had control.

What unsettles me most is how normalized this has become. We are living in a world where forgetting is no longer guaranteed. Every mistake, every private image, every personal file can potentially exist indefinitely. That reality makes privacy feel less like a right and more like a temporary illusion.

At the end of the day, this case made me question whether modern technology is being built for human dignity or for data permanence. Deletion should be final. If we can permanently erase physical objects, then we should also be able to permanently erase digital ones. Until that becomes the default, “delete” will remain one of the most misleading buttons we use every day.