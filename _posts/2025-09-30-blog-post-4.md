---
title: "How Generative AI Works and Where It Fails"
date: 2025-09-30
permalink: /posts/2025/09/genai-blog2/
tags:
  - ai
  - ethics
  - environment
collection: blogs
---

**Article Reading:**  
[How Generative AI Works and How It Fails — Arvind Narayanan & Sayash Kapoor](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)  

---

## Summary  
This case study breaks down how generative AI creates text and images, and why these systems often fail in unexpected ways. It also highlights ethical concerns like misinformation, deepfakes, and the labor needed to train and maintain these models. The bigger theme is how society should respond as AI becomes more central to daily life.

## Discussion: Environmental Impact  
Large AI systems demand real resources. Some studies estimate that training a single large model can emit **as much carbon as several cars over their full lifetime**, depending on the energy source. Even after training, the constant compute needed to run AI tools requires electricity, cooling systems, and large amounts of water—Google and Microsoft have both reported big increases in their energy and water usage because of AI expansion.

Policies are still catching up. The EU has pushed for transparency around AI emissions, while the U.S. has begun studying data center impact, but renewable energy adoption is inconsistent. From the user perspective, none of this is visible. We interact with clean interfaces, not with the power demands behind them.

For me, this became more real when I started using AI to support my own work. I use it to elevate my coding—letting me explore frameworks and design patterns I’m not fully fluent in yet. It opens doors, but it also comes with guilt. I used to take pride in not relying on AI, and suddenly I needed the time it saved. That tension makes the environmental cost feel more personal: if I’m benefiting from this technology, then I’m also participating in the footprint it leaves.

Looking ahead, AI might not replace one tool like Google, but instead become a platform that connects everything. The question is whether we can grow those systems responsibly, or whether we’ll let convenience expand faster than sustainability plans.

## Reflection  
I rarely trust AI completely—especially in coding. I always build off my own work and test everything myself. But even with that caution, I still wonder whether using AI makes me a little too comfortable. It saves time, but at the cost of discipline. I guess that’s the pattern with every era of technology: excitement, usefulness, guilt, and an ongoing question about whether it makes us sharper or just makes the work easier.